{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.layers import LSTM, GlobalAveragePooling1D, Dense, Dropout, Masking, Input, BatchNormalization, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.activations import sigmoid, relu\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"./Input/\"\n",
    "types = [\"Lunges\", \"BodyWeightSquats\", \"PushUps\"] # only classifying between these\n",
    "extension = \"*.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     exercise          example  frame    NOSE.x    NOSE.y    NOSE.z    NOSE.v  \\\n",
      "0      Lunges   Lunges_g01_c01      0  0.628940  0.190160 -1.083234  1.000000   \n",
      "1      Lunges   Lunges_g01_c01      1  0.634642  0.184615 -0.862562  1.000000   \n",
      "2      Lunges   Lunges_g01_c01      2  0.635383  0.177477 -0.976451  1.000000   \n",
      "3      Lunges   Lunges_g01_c01      3  0.635381  0.176862 -0.991717  1.000000   \n",
      "4      Lunges   Lunges_g01_c01      4  0.632972  0.182430 -0.895682  1.000000   \n",
      "...       ...              ...    ...       ...       ...       ...       ...   \n",
      "8250  PushUps  PushUps_g25_c04     96  0.641914  0.718347 -0.041630  0.998482   \n",
      "8251  PushUps  PushUps_g25_c04     97  0.643355  0.712380 -0.097662  0.998587   \n",
      "8252  PushUps  PushUps_g25_c04     98  0.643144  0.702161 -0.131786  0.998672   \n",
      "8253  PushUps  PushUps_g25_c04     99  0.636427  0.693687 -0.098183  0.998680   \n",
      "8254  PushUps  PushUps_g25_c04    100  0.638258  0.684618 -0.092309  0.998744   \n",
      "\n",
      "      LEFT_EYE_INNER.x  LEFT_EYE_INNER.y  LEFT_EYE_INNER.z  ...  RIGHT_HEEL.z  \\\n",
      "0             0.637373          0.149968         -1.077586  ...      0.803369   \n",
      "1             0.639514          0.145265         -0.857735  ...      0.472490   \n",
      "2             0.641203          0.139931         -0.971706  ...      0.525471   \n",
      "3             0.641786          0.137734         -0.989160  ...      0.702304   \n",
      "4             0.640021          0.141749         -0.900764  ...      0.569629   \n",
      "...                ...               ...               ...  ...           ...   \n",
      "8250          0.654601          0.712731         -0.040193  ...      0.050421   \n",
      "8251          0.655464          0.706468         -0.090782  ...      0.067876   \n",
      "8252          0.654846          0.695205         -0.120915  ...      0.061051   \n",
      "8253          0.648859          0.686798         -0.088198  ...      0.069688   \n",
      "8254          0.649887          0.676210         -0.083211  ...      0.152379   \n",
      "\n",
      "      RIGHT_HEEL.v  LEFT_FOOT_INDEX.x  LEFT_FOOT_INDEX.y  LEFT_FOOT_INDEX.z  \\\n",
      "0         0.451993           0.666825           0.935780           0.647691   \n",
      "1         0.745581           0.675913           0.946760           0.564102   \n",
      "2         0.633097           0.679753           0.947393           0.588786   \n",
      "3         0.729385           0.676028           0.948587           0.682787   \n",
      "4         0.633890           0.677371           0.954212           0.636038   \n",
      "...            ...                ...                ...                ...   \n",
      "8250      0.958218           0.153113           0.723934           0.297861   \n",
      "8251      0.958957           0.153923           0.724947           0.319272   \n",
      "8252      0.958011           0.142008           0.713899           0.308427   \n",
      "8253      0.956502           0.140524           0.713107           0.302956   \n",
      "8254      0.957017           0.141569           0.715851           0.377960   \n",
      "\n",
      "      LEFT_FOOT_INDEX.v  RIGHT_FOOT_INDEX.x  RIGHT_FOOT_INDEX.y  \\\n",
      "0              0.837018            0.508485            0.906145   \n",
      "1              0.928626            0.513611            0.923711   \n",
      "2              0.758095            0.524267            0.923373   \n",
      "3              0.818430            0.527595            0.923627   \n",
      "4              0.809525            0.523841            0.925313   \n",
      "...                 ...                 ...                 ...   \n",
      "8250           0.662029            0.116872            0.727545   \n",
      "8251           0.669273            0.115900            0.726388   \n",
      "8252           0.669626            0.114429            0.725023   \n",
      "8253           0.663653            0.114430            0.723275   \n",
      "8254           0.666592            0.118812            0.724260   \n",
      "\n",
      "      RIGHT_FOOT_INDEX.z  RIGHT_FOOT_INDEX.v  \n",
      "0               0.640605            0.781718  \n",
      "1               0.327982            0.919039  \n",
      "2               0.355356            0.797511  \n",
      "3               0.550238            0.833113  \n",
      "4               0.457674            0.760873  \n",
      "...                  ...                 ...  \n",
      "8250           -0.008316            0.962777  \n",
      "8251            0.002076            0.963625  \n",
      "8252           -0.009581            0.962957  \n",
      "8253            0.001679            0.960911  \n",
      "8254            0.085674            0.960304  \n",
      "\n",
      "[51531 rows x 135 columns]\n"
     ]
    }
   ],
   "source": [
    "main_df = pd.DataFrame()\n",
    "\n",
    "for count, cur in enumerate(types):\n",
    "    current_glob = glob.glob(datapath+cur+\"/\"+extension)\n",
    "    df = pd.DataFrame()\n",
    "    li = []\n",
    "\n",
    "    for filename in current_glob:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        p = re.compile(\"v_(.*)\\.csv\")\n",
    "        filename = p.findall(filename)[0]\n",
    "        df.insert(0, 'example', filename)\n",
    "        df.insert(0, 'exercise', cur)\n",
    "        li.append(df)\n",
    "\n",
    "    frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "    if count == 0:\n",
    "        main_df = pd.DataFrame(columns=frame.columns, data=frame)\n",
    "    else:\n",
    "        main_df = pd.concat([main_df, frame])\n",
    "\n",
    "\n",
    "print(main_df.head(100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Maximum Number of Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_frames = main_df.frame.max() + 1\n",
    "print(max_frames)\n",
    "plt.boxplot(main_df.frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate $\\hat{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339\n",
      "                          BodyWeightSquats  Lunges  PushUps\n",
      "example                                                    \n",
      "BodyWeightSquats_g01_c01                 1       0        0\n",
      "BodyWeightSquats_g01_c02                 1       0        0\n",
      "BodyWeightSquats_g01_c03                 1       0        0\n",
      "BodyWeightSquats_g01_c04                 1       0        0\n",
      "BodyWeightSquats_g02_c01                 1       0        0\n",
      "...                                    ...     ...      ...\n",
      "PushUps_g24_c04                          0       0        1\n",
      "PushUps_g25_c01                          0       0        1\n",
      "PushUps_g25_c02                          0       0        1\n",
      "PushUps_g25_c03                          0       0        1\n",
      "PushUps_g25_c04                          0       0        1\n",
      "\n",
      "[339 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(len(pd.unique(main_df.example)))\n",
    "#print(main_df.head())\n",
    "yhat = main_df.groupby(by=\"example\").exercise.max()\n",
    "\n",
    "yhat = pd.get_dummies(yhat)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Padding to Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "video_frames = []\n",
    "\n",
    "NUM_FEATURES = 132\n",
    "\n",
    "for video in main_df.groupby(by=\"example\"):\n",
    "    current = video[1]\n",
    "    current = current.drop(columns=[\"exercise\",\"frame\",\"example\"])\n",
    "    current = current.to_numpy()\n",
    "    #print(current.shape)\n",
    "    #print(type(current))\n",
    "    np.nan_to_num(current, copy=False, nan=-2.)\n",
    "    padded = np.ones((max_frames, NUM_FEATURES))\n",
    "    padded *= -2. # Number not between -1 and 1\n",
    "    padded[0:current.shape[0],:] = current\n",
    "    video_frames.append(padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339, 271, 132)\n",
      "(339, 3)\n"
     ]
    }
   ],
   "source": [
    "x = np.stack(video_frames, axis=0)\n",
    "print(x.shape)\n",
    "print(yhat.shape)\n",
    "#214 => 341 is the video count\n",
    "#267 => 271 is max length of a video\n",
    "#132 is the number of features per frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.46866941,  0.06936088, -0.10580542, ...,  0.8293696 ,\n",
       "         0.18381335,  0.28686142],\n",
       "       [ 0.46866211,  0.06987888, -0.10384705, ...,  0.83663428,\n",
       "         0.28486028,  0.31443235],\n",
       "       [ 0.46861085,  0.07002214, -0.09624683, ...,  0.85010797,\n",
       "         0.24064758,  0.34029156],\n",
       "       ...,\n",
       "       [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "        -2.        , -2.        ],\n",
       "       [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "        -2.        , -2.        ],\n",
       "       [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "        -2.        , -2.        ]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]\n",
    "#What are the features, keypoint, x, y ,z so nose, shoulder, hand, elbow, etc.\n",
    "#These are points in 3d space?yes, localized\n",
    "#and you have params set up for all the different parts of the body to track?\n",
    "#How much data do you have? Gonna need a fuckin lot of it to train this, yeah , i was thinking we need more data\n",
    "#Your network is tiny as well for this. For our very simple lstm it's double the size of yours and also deeper\n",
    "\n",
    "#some of these numbers are the same, you can one hot encode them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271, 271, 132)\n",
      "(68, 271, 132)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, yhat, test_size=0.2)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model\n",
    "## TODO: Fix Gradient Explosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 375ms/step - loss: 3.3653 - accuracy: 0.3274\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_20 (Masking)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "lstm_40 (LSTM)               multiple                  50432     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             multiple                  195       \n",
      "=================================================================\n",
      "Total params: 50,627\n",
      "Trainable params: 50,627\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Optimizer\n",
    "#opt = Adam(learning_rate=0.1, clipnorm=1)#clipvalue=0.5\n",
    "opt = RMSprop(learning_rate=0.1)#, clipvalue=0.5)\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Input(x.shape)) #put the network shapes\n",
    "model.add(Masking(mask_value=-2.))\n",
    "model.add(LSTM(64,\n",
    "               input_shape=((x.shape[1],x.shape[2])), # put the shape of the network\n",
    "               recurrent_dropout=0,#.3,\n",
    "               #return_sequences=True,\n",
    "               dtype='float32'))#, activation='tanh'))\n",
    "model.add(GlobalAveragePooling1D(dtype='float32'))\n",
    "#model.add(LSTM(64, dtype='float32'))\n",
    "#model.add(BatchNormalization(dtype='float32'))\n",
    "#model.add(Dropout(0.3, dtype='float32'))\n",
    "#model.add(Dense(32, activation='tanh', dtype='float32'))#activation='relu', activation=\"softmax\"\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(Activation('tanh'))#relu\n",
    "#model.add(Dense(32, activation='tanh', dtype='float32'))#relu\n",
    "#model.add(Dropout(0.3, dtype='float32'))#0.3, \n",
    "model.add(Dense(len(types), activation='softmax', dtype='float32'))\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "#model.add(SimpleRNN(128, dtype='float64'))\n",
    "#model.add(LSTM(128, return_sequences=True, recurrent_dropout=0, dtype='float32'))\n",
    "#model.add(LSTM(128, dtype='float32'))#, activation='tanh'))\n",
    "#model.add(BatchNormalization(dtype='float32'))\n",
    "#model.add(Dropout(0, dtype='float32'))\n",
    "#model.add(Dropout(0, dtype='float32'))\n",
    "#model.add(Dense(128, activation='tanh'))#softmax\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "#model.add(BatchNormalization(dtype='float32'))\n",
    "#model.add(Dropout(0, dtype='float32'))\n",
    "#model.add(Dense(64, activation=\"softmax\"))#softmax\n",
    "#model.add(Dense(len(types), activation='softmax', dtype='float32'))#, activation=\"softmax\"\n",
    "#model.add(BatchNormalization(dtype='float32'))\n",
    "#model.add(Dropout(0, dtype='float32'))\n",
    "#model.add(LeakyReLU(alpha=0.1, dtype='float64'))\n",
    "#model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "#model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x, yhat)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "34/34 [==============================] - 14s 407ms/step - loss: 2.0707 - accuracy: 0.4280 - val_loss: 2.4085 - val_accuracy: 0.3088\n",
      "Epoch 2/5\n",
      "34/34 [==============================] - 13s 380ms/step - loss: 2.5268 - accuracy: 0.3395 - val_loss: 4.4672 - val_accuracy: 0.3676\n",
      "Epoch 3/5\n",
      "34/34 [==============================] - 14s 407ms/step - loss: 2.3007 - accuracy: 0.3284 - val_loss: 1.7588 - val_accuracy: 0.3676\n",
      "Epoch 4/5\n",
      "34/34 [==============================] - 12s 361ms/step - loss: 2.4321 - accuracy: 0.3210 - val_loss: 3.6323 - val_accuracy: 0.3676\n",
      "Epoch 5/5\n",
      "34/34 [==============================] - 14s 412ms/step - loss: 1.7511 - accuracy: 0.3985 - val_loss: 1.3053 - val_accuracy: 0.3088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7d157529e8>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=8, epochs=5, validation_data=(x_test, y_test))\n",
    "#model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n",
    "#model.fit(x, yhat, batch_size=32, epochs=10, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model\n",
    "Saves the model to a h5 file to be used for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('poseNetworkLSTM.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy is around 33%, basically guessing, also not learning, which is likely from the loss being nan\n",
    "#batch normalization got rid of nan loss but did not learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.isnan(x_train)\n",
    "np.isnan(x_test)\n",
    "#assert not np.any(np.isnan(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.30873084,  0.44448707, -0.32377079, ...,  0.43006051,\n",
       "          0.68181825,  0.27283329],\n",
       "        [ 0.31388295,  0.44408581, -0.40807772, ...,  0.42295274,\n",
       "          0.67439413,  0.26972276],\n",
       "        [ 0.3157241 ,  0.44592893, -0.42466444, ...,  0.41555202,\n",
       "          0.66938913,  0.26348847],\n",
       "        ...,\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ]],\n",
       "\n",
       "       [[ 0.51756209,  0.33402985, -0.74317491, ...,  0.93503976,\n",
       "         -0.22448032,  0.9925518 ],\n",
       "        [ 0.51890945,  0.33931226, -0.70216596, ...,  0.93708634,\n",
       "         -0.29486123,  0.99280238],\n",
       "        [ 0.52325141,  0.34800079, -0.65835208, ...,  0.93772608,\n",
       "         -0.35195339,  0.99324012],\n",
       "        ...,\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ]],\n",
       "\n",
       "       [[ 0.40722686,  0.16950601, -1.15044725, ...,  0.68915248,\n",
       "          1.01125562,  0.28474072],\n",
       "        [ 0.4068242 ,  0.17724697, -0.97166348, ...,  0.68944389,\n",
       "          0.83046901,  0.26830551],\n",
       "        [ 0.40620628,  0.19199751, -1.00246358, ...,  0.66533399,\n",
       "          0.90380228,  0.25038975],\n",
       "        ...,\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.48332396,  0.13197485, -0.44448036, ...,  0.78283352,\n",
       "         -0.03181785,  0.99225968],\n",
       "        [ 0.48338214,  0.13046856, -0.37762433, ...,  0.78323573,\n",
       "         -0.05867266,  0.99210888],\n",
       "        [ 0.48360857,  0.12839293, -0.38013008, ...,  0.78372598,\n",
       "         -0.05152659,  0.99182165],\n",
       "        ...,\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ]],\n",
       "\n",
       "       [[        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan],\n",
       "        [        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan],\n",
       "        [        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan],\n",
       "        ...,\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ]],\n",
       "\n",
       "       [[ 0.2843715 ,  0.4622547 , -0.29464743, ...,  0.46734372,\n",
       "          0.60803884,  0.21690598],\n",
       "        [ 0.28645137,  0.48219603, -0.30222481, ...,  0.46345094,\n",
       "          0.65073144,  0.22533095],\n",
       "        [ 0.29216245,  0.50258166, -0.31803912, ...,  0.45011297,\n",
       "          0.69210178,  0.23504883],\n",
       "        ...,\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.30873084,  0.44448707, -0.32377079, ...,  0.43006051,\n",
       "          0.68181825,  0.27283329],\n",
       "        [ 0.31388295,  0.44408581, -0.40807772, ...,  0.42295274,\n",
       "          0.67439413,  0.26972276],\n",
       "        [ 0.3157241 ,  0.44592893, -0.42466444, ...,  0.41555202,\n",
       "          0.66938913,  0.26348847],\n",
       "        ...,\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ]],\n",
       "\n",
       "       [[ 0.51756209,  0.33402985, -0.74317491, ...,  0.93503976,\n",
       "         -0.22448032,  0.9925518 ],\n",
       "        [ 0.51890945,  0.33931226, -0.70216596, ...,  0.93708634,\n",
       "         -0.29486123,  0.99280238],\n",
       "        [ 0.52325141,  0.34800079, -0.65835208, ...,  0.93772608,\n",
       "         -0.35195339,  0.99324012],\n",
       "        ...,\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ]],\n",
       "\n",
       "       [[ 0.40722686,  0.16950601, -1.15044725, ...,  0.68915248,\n",
       "          1.01125562,  0.28474072],\n",
       "        [ 0.4068242 ,  0.17724697, -0.97166348, ...,  0.68944389,\n",
       "          0.83046901,  0.26830551],\n",
       "        [ 0.40620628,  0.19199751, -1.00246358, ...,  0.66533399,\n",
       "          0.90380228,  0.25038975],\n",
       "        ...,\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.48332396,  0.13197485, -0.44448036, ...,  0.78283352,\n",
       "         -0.03181785,  0.99225968],\n",
       "        [ 0.48338214,  0.13046856, -0.37762433, ...,  0.78323573,\n",
       "         -0.05867266,  0.99210888],\n",
       "        [ 0.48360857,  0.12839293, -0.38013008, ...,  0.78372598,\n",
       "         -0.05152659,  0.99182165],\n",
       "        ...,\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ]],\n",
       "\n",
       "       [[        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan],\n",
       "        [        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan],\n",
       "        [        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan],\n",
       "        ...,\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ]],\n",
       "\n",
       "       [[ 0.2843715 ,  0.4622547 , -0.29464743, ...,  0.46734372,\n",
       "          0.60803884,  0.21690598],\n",
       "        [ 0.28645137,  0.48219603, -0.30222481, ...,  0.46345094,\n",
       "          0.65073144,  0.22533095],\n",
       "        [ 0.29216245,  0.50258166, -0.31803912, ...,  0.45011297,\n",
       "          0.69210178,  0.23504883],\n",
       "        ...,\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ],\n",
       "        [-2.        , -2.        , -2.        , ..., -2.        ,\n",
       "         -2.        , -2.        ]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9,  18,   0],\n",
       "       [  9,  18,   1],\n",
       "       [  9,  18,   2],\n",
       "       ...,\n",
       "       [329,   0, 129],\n",
       "       [329,   0, 130],\n",
       "       [329,   0, 131]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(np.isnan(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
       "       -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
       "       -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
       "       -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
       "       -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
       "       -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
       "       -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
       "       -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
       "       -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
       "       -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
       "       -2., -2.])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[9][18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
